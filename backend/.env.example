# AI Provider Configuration
# Options: "bedrock" (default for production) or "openai" (for local development)
AI_PROVIDER=bedrock

# AWS Bedrock Configuration (used when AI_PROVIDER=bedrock)
BEDROCK_MODEL_ID=eu.amazon.nova-lite-v1:0
DEFAULT_AWS_REGION=eu-west-1

# OpenAI Configuration (used when AI_PROVIDER=openai)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4o-mini

# CORS Configuration
# Comma-separated list of allowed origins for CORS
CORS_ORIGINS=http://localhost:3000

# Memory Storage Configuration
# Set to "true" to use S3 for conversation memory (production)
# Set to "false" to use local file storage (local development)
USE_S3=false
S3_BUCKET=
MEMORY_DIR=../memory

# Personal Data Storage (for Lambda deployment)
# S3 bucket name where personal data files are stored
PERSONAL_DATA_BUCKET=

# Data Encryption (optional - for encrypted data files)
# Encryption key for decrypting personal data files
DATA_KEY=

# GitHub Configuration (optional - for downloading encrypted data from releases)
# Private repository name (format: owner/repo-name)
PRIVATE_REPO_NAME=
# GitHub personal access token (required for private repos)
GITHUB_TOKEN=
